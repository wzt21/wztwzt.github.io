<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Wonder zone的学习日志</title><link>https://wzt21.github.io/wztwzt.github.io</link><description>这是一个记录各种学习情况的日志，主要聚焦于计算机、数学、物理学，以及Wonder Zone的求学经历等等</description><copyright>Wonder zone的学习日志</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://wzt21.github.io/wztwzt.github.io</link></image><lastBuildDate>Sun, 21 Dec 2025 11:54:18 +0000</lastBuildDate><managingEditor>Wonder zone的学习日志</managingEditor><ttl>60</ttl><webMaster>Wonder zone的学习日志</webMaster><item><title>论文阅读-Deep Residual Learning for Image Recognition</title><link>https://wzt21.github.io/wztwzt.github.io/post/lun-wen-yue-du--Deep%20Residual%20Learning%20for%20Image%20Recognition.html</link><description>残差神经网络：

&lt;img width='650' height='365' alt='Image' src='https://github.com/user-attachments/assets/938de5ce-232c-4bf9-a725-c2ac03d050fa' /&gt;

深度残差学习

F(x)+x 的公式可以通过具有“快捷连接”的前馈神经网络实现（图 2）。</description><guid isPermaLink="true">https://wzt21.github.io/wztwzt.github.io/post/lun-wen-yue-du--Deep%20Residual%20Learning%20for%20Image%20Recognition.html</guid><pubDate>Sun, 21 Dec 2025 11:53:46 +0000</pubDate></item><item><title>**Dropout: A Simple Way to Prevent Neural Networks from  Overfitting 论文阅读**</title><link>https://wzt21.github.io/wztwzt.github.io/post/--Dropout-%20A%20Simple%20Way%20to%20Prevent%20Neural%20Networks%20from%20%20Overfitting%20-lun-wen-yue-du---.html</link><description>**Dropout: A Simple Way to Prevent Neural Networks from  Overfitting**

net would become robust against dropout by manking many copies of each hidden unit,but this is a poor solution for exactly the same reason as **replica codes are a a poor way to deal with a noisy channel.**

dropout 模型
标准神经网络的前向操作：

&lt;img width='363' height='98' alt='Image' src='https://github.com/user-attachments/assets/9ea8e2c1-f063-4c3b-afa0-cb6890bde106' /&gt;

f激活函数
带有dropout的前向操作：

&lt;img width='352' height='192' alt='Image' src='https://github.com/user-attachments/assets/85c735c8-665b-4a23-9eca-67d6b3304bae' /&gt;

&lt;!-- Failed to upload 'image.png' --&gt;

最大范数正则化

&lt;img width='966' height='226' alt='Image' src='https://github.com/user-attachments/assets/fa2d1658-39a4-4f4a-8ad8-70df59f4c3d2' /&gt;

无监督预训练
预训练获得的权重应除以p

贝叶斯神经网络？

对特征的影响
We hypothesize that for each hidden unit, dropout prevents co-adaptation by making the presence of other hidden units unreliable. Therefore, a hidden unit cannot rely on other specific units to correct its mistakes. It must perform well in a wide variety of different contexts provided by the other hidden units.

在不使用随机性的情况下获得 dropout 的一些好处的一种方法是边缘化噪声，以获得一个在期望上与 dropout 过程作用相同的正则化器。</description><guid isPermaLink="true">https://wzt21.github.io/wztwzt.github.io/post/--Dropout-%20A%20Simple%20Way%20to%20Prevent%20Neural%20Networks%20from%20%20Overfitting%20-lun-wen-yue-du---.html</guid><pubDate>Sun, 21 Dec 2025 08:01:48 +0000</pubDate></item><item><title>大模型学习日记-第一周计划</title><link>https://wzt21.github.io/wztwzt.github.io/post/da-mo-xing-xue-xi-ri-ji---di-yi-zhou-ji-hua.html</link><description>4篇论文
看懂公式为主
实验：具体参数，如层数、宽度、学习率、数据大小
附录

代码方面？。</description><guid isPermaLink="true">https://wzt21.github.io/wztwzt.github.io/post/da-mo-xing-xue-xi-ri-ji---di-yi-zhou-ji-hua.html</guid><pubDate>Wed, 17 Dec 2025 14:45:19 +0000</pubDate></item><item><title>大模型攻略</title><link>https://wzt21.github.io/wztwzt.github.io/post/da-mo-xing-gong-lve.html</link><description>下面是一份由智谱清言生成的大模型学习攻略。</description><guid isPermaLink="true">https://wzt21.github.io/wztwzt.github.io/post/da-mo-xing-gong-lve.html</guid><pubDate>Wed, 17 Dec 2025 14:30:16 +0000</pubDate></item><item><title>大模型学习攻略</title><link>https://wzt21.github.io/wztwzt.github.io/post/da-mo-xing-xue-xi-gong-lve.html</link><description>下面是一份由智谱清言生成的大模型学习攻略。</description><guid isPermaLink="true">https://wzt21.github.io/wztwzt.github.io/post/da-mo-xing-xue-xi-gong-lve.html</guid><pubDate>Wed, 17 Dec 2025 14:25:14 +0000</pubDate></item><item><title>This is a start of some wonderful things.</title><link>https://wzt21.github.io/wztwzt.github.io/post/This%20is%20a%20start%20of%20some%20wonderful%20things..html</link><description>bruh bruh Maechel Bellic.。</description><guid isPermaLink="true">https://wzt21.github.io/wztwzt.github.io/post/This%20is%20a%20start%20of%20some%20wonderful%20things..html</guid><pubDate>Fri, 12 Dec 2025 09:50:05 +0000</pubDate></item></channel></rss>